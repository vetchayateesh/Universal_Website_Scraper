# ğŸŒ Universal Website Scraper

A **Universal Website Scraper** built to extract structured, section-aware content from **any website** â€” including **static pages and JavaScript-rendered sites**.  
It returns clean **JSON output** and provides a **simple frontend viewer** to explore and download the scraped data.

This project was built as an **MVP Full-Stack Assignment** focusing on robustness, clarity, and real-world scraping scenarios.

---

## ğŸš€ Features

- ğŸ” Scrapes **static & JS-rendered websites**
- ğŸ§  **Automatic fallback** from static scraping â†’ Playwright rendering
- ğŸ–±ï¸ Handles **click flows** (tabs, â€œLoad moreâ€, show more buttons)
- ğŸ“œ Supports **scrolling & pagination** (depth â‰¥ 3)
- ğŸ§© Groups content into **logical sections** (Hero, Nav, Footer, FAQ, etc.)
- ğŸ“¦ Outputs **section-aware structured JSON**
- ğŸ–¥ï¸ Minimal **frontend UI** to:
  - Input URL
  - View parsed sections
  - Expand JSON per section
  - Download full JSON result
- ğŸ›¡ï¸ Graceful error handling with partial results

---

## ğŸ› ï¸ Tech Stack

### Backend
- **Python 3.10+**
- **FastAPI**
- **httpx / requests**
- **BeautifulSoup / lxml**
- **Playwright (Python)** â€“ for JS rendering
- **Uvicorn**

### Frontend
- Minimal HTML / Jinja2 based UI  
- JSON viewer with expandable sections

---

## ğŸ“‚ Project Structure

